{
	"nodes":[
		{"id":"90cec71e9bb2b6e7","type":"text","text":"Text Summarization","x":-87,"y":-317,"width":250,"height":60},
		{"id":"aae8dc8f89f6adc9","type":"text","text":"The process of condensing information in one or more documents to make it suitable for a designated task or user (Carichon et al., 2023; Altmami & Menai, 2022) while maintaining the accuracy of its content (Rahman et al., 2021)","x":-136,"y":-680,"width":348,"height":176,"color":"4"},
		{"id":"a52056f02595ba82","type":"text","text":"Word Sense Disambiguation","x":-640,"y":-316,"width":270,"height":60,"color":"4"},
		{"id":"6596d1f2650db256","type":"text","text":"BERTScore","x":-1944,"y":-171,"width":250,"height":60},
		{"id":"f5fb2b7887673b15","type":"text","text":"Cosine similarity can be computed based on different types of word embeddings, such as word2vec, GloVe, or BERT. [Cosine similarity can be used to compare a summary with the original text or with a reference summary, or to compare multiple summaries with each other](https://aclanthology.org/2021.icon-main.17.pdf)","x":-2903,"y":99,"width":865,"height":116},
		{"id":"d8d2231a8f7374f7","type":"text","text":"This is a novel method that uses large language models (LLMs) such as gpt-4 as evaluators for abstractive summarization. G-Eval does not require any reference output, but instead uses the LLM’s internal scoring mechanism to rank the system outputs. G-Eval can capture the fluency, coherence, and informativeness of the outputs, as well as the style and tone of the LLM.","x":-2903,"y":-61,"width":865,"height":130},
		{"id":"b9419e6c934ae2e3","type":"text","text":"This stands for Recall-Oriented Understudy for Gisting Evaluation, and it measures the overlap of n-grams (sequences of n words) between the system output and the reference output. ROUGE has different variants, such as ROUGE-N, ROUGE-L, and ROUGE-S, that use different types of n-grams. ROUGE is widely used for text summarization evaluation, as it can capture the content similarity between the outputs.","x":-2903,"y":-337,"width":858,"height":122},
		{"id":"0c9064f04dd4ee64","type":"text","text":"This leverages the pre-trained contextual embeddings from BERT and matches words in the system output and the reference output by cosine similarity. BERTScore can capture the semantic similarity between the outputs, as well as the word order and position. BERTScore can be used for both WSD and text summarization evaluation, as it can handle synonyms, paraphrases, and word sense variations.","x":-2903,"y":-195,"width":865,"height":109},
		{"id":"3189b4c968947b73","type":"text","text":"Cosine Similarity","x":-1944,"y":127,"width":250,"height":60},
		{"id":"216fd7d002d3fe5d","type":"text","text":"G-Eval","x":-1944,"y":-26,"width":250,"height":60},
		{"id":"be8a256b3777488d","type":"text","text":"ROGUE / F-Measure","x":-1944,"y":-305,"width":250,"height":60},
		{"id":"0d2b249776ff9773","type":"text","text":"This involves combining multiple methods","x":-2323,"y":-880,"width":655,"height":60,"color":"4"},
		{"id":"4b7cbbab26e16db5","type":"text","text":"Many words have multiple meanings, and some meanings are more common or specific than others. Moreover, the meaning of a word can change depending on the domain, genre, or style of the text.","x":-2323,"y":-761,"width":655,"height":82,"color":"4"},
		{"id":"ccb3dde52b1bd5f5","type":"text","text":"There is not enough data that is labeled with the correct senses of words, and creating such data is costly and time-consuming. Moreover, different sources of data may use different sense inventories or definitions, which can cause inconsistency and confusion.","x":-2323,"y":-661,"width":661,"height":120,"color":"4"},
		{"id":"63c8f4172518c95e","type":"text","text":"There is no standard way to measure the accuracy and quality of WSD systems, and different evaluation metrics may favor different methods or aspects of WSD. Moreover, the human agreement on the correct senses of words is not always high, which can affect the reliability and validity of the evaluation.","x":-2323,"y":-526,"width":664,"height":125,"color":"3"},
		{"id":"99ecbf6c5803bc3f","type":"text","text":"Supervised Learning","x":-1540,"y":-1221,"width":250,"height":60,"color":"3"},
		{"id":"44e691f54b852429","type":"text","text":"Unsupervised Learning","x":-1540,"y":-1107,"width":250,"height":60,"color":"1"},
		{"id":"0f12e35dbc77bd46","type":"text","text":"Knowledge-based Learning","x":-1540,"y":-993,"width":250,"height":60,"color":"3"},
		{"id":"4cba1b3b04c46682","type":"text","text":"Hybrid","x":-1540,"y":-880,"width":250,"height":60,"color":"4"},
		{"id":"bcde28ab5ef3abc2","type":"text","text":"Methods","x":-1040,"y":-1033,"width":250,"height":60,"color":"4"},
		{"id":"12ba9d718f56f0cc","type":"text","text":"The Ambiguity and Variability of Natural Language","x":-1540,"y":-761,"width":250,"height":82,"color":"4"},
		{"id":"e868388bf8a96d92","type":"text","text":"Challenges","x":-1040,"y":-641,"width":250,"height":60},
		{"id":"77b585d12f204d43","type":"text","text":"The Lack of Annotated Data","x":-1540,"y":-631,"width":250,"height":60,"color":"4"},
		{"id":"6660aca082f74dc0","type":"text","text":"The Evaluation of WSD","x":-1540,"y":-493,"width":250,"height":60,"color":"3"},
		{"id":"4f376e4542b3c237","type":"text","text":"Human Evaluation","x":-1540,"y":-335,"width":250,"height":60,"color":"4"},
		{"id":"266d164a58e929bb","type":"text","text":"Evaluation","x":-1039,"y":-213,"width":250,"height":60},
		{"id":"ccbe89ec97449441","type":"text","text":"Automatic Evaluation","x":-1540,"y":-91,"width":250,"height":60,"color":"4"},
		{"id":"db2642e5d30ad0d5","type":"text","text":"[Some of the common supervised learning algorithms for WSD are decision trees, naive Bayes, support vector machines, and neural networks](https://www.degruyter.com/document/doi/10.1515/jib-2017-0051/html)","x":-3040,"y":-1221,"width":606,"height":60,"color":"3"},
		{"id":"3b426eb70886cfc2","type":"text","text":" [Some of the common knowledge based methods for WSD are Lesk algorithm, vector space model, graph-based methods, and word embeddings](https://www.degruyter.com/document/doi/10.1515/jib-2017-0051/html)","x":-3036,"y":-1011,"width":602,"height":97,"color":"3"},
		{"id":"46bf6cd2fcfe4d3f","type":"text","text":"Supervised Learning and Knowledge-based Learning","x":-3036,"y":-880,"width":602,"height":60,"color":"4"},
		{"id":"d29ce87c068e22b2","type":"text","text":"This involves training a machine learning model on a dataset of examples, where each example contains a word and its correct sense in a specific context. The model then learns to predict the correct sense of a word in new contexts.","x":-2323,"y":-1238,"width":655,"height":94,"color":"3"},
		{"id":"26bb0b984e5bc95e","type":"text","text":"This involves grouping words that appear in similar contexts together, and then assigning senses to the resulting groups. This method does not require any labeled data, but it is less accurate than supervised learning.","x":-2323,"y":-1119,"width":655,"height":84,"color":"1"},
		{"id":"4f49bc8097c8b200","type":"text","text":"This involves using a knowledge base, such as a dictionary or an ontology, to map words to their different senses. This method relies on the availability and quality of the knowledge base.","x":-2323,"y":-1003,"width":655,"height":80,"color":"3"},
		{"id":"70364c142da1dadc","type":"text","text":"The **process** of identifying which meaning of a word is intended in a given context.","x":-1111,"y":-1201,"width":471,"height":80,"color":"4"},
		{"id":"2bb6bf5b7a9df6f0","type":"text","text":"Application","x":-1039,"y":400,"width":250,"height":60},
		{"id":"13c2b5929f44cce4","type":"text","text":"Areas WSD is Needed","x":-1039,"y":1029,"width":250,"height":60},
		{"id":"be3172ffa589942f","type":"text","text":"Education","x":-1540,"y":684,"width":250,"height":60},
		{"id":"0f75e034b5ae2f3c","type":"text","text":"Tourism","x":-1540,"y":857,"width":250,"height":60},
		{"id":"4501943dcecc92d9","type":"text","text":"News","x":-1540,"y":1028,"width":250,"height":60},
		{"id":"cc8c96281fecf1cc","type":"text","text":"Legal","x":-1540,"y":1207,"width":250,"height":60},
		{"id":"df08c877e98f46ac","type":"text","text":"Medical / Healthcare","x":-1540,"y":1399,"width":250,"height":60},
		{"id":"59fa4ae03e12eb23","type":"text","text":"These texts contain many words and names that have different meanings and associations in different regions, cultures, or events. For example, the word “apple” can mean a fruit, a company, or a city, depending on the context. WSD can help to determine the correct sense of these words and names for the text and the query. [This can increase the informativeness and conciseness of the summaries for news texts, which are often used for entertainment, education, or awareness purposes](https://direct.mit.edu/coli/article/47/2/387/98520/Analysis-and-Evaluation-of-Language-Models-for)","x":-2600,"y":1000,"width":962,"height":118},
		{"id":"7570e9561d79be61","type":"text","text":"These texts contain many words and phrases that have specific and formal meanings in the legal domain, and that may differ from their common meanings. For example, the word “charge” can mean a fee, an accusation, or an electric current, depending on the context. WSD can help to identify the correct sense of these words and phrases for the text and the query. [This can enhance the readability and coherence of the summaries for legal texts, which are often used for decision making, analysis, or information retrieval purposes](https://academic.oup.com/edited-volume/42643/chapter/358151797)","x":-2598,"y":1160,"width":958,"height":156},
		{"id":"70028197c6b314fb","type":"text","text":"These texts contain many technical terms, acronyms, and abbreviations that have multiple meanings and senses. For example, the word “cell” can mean a biological unit, a prison room, or a terrorist group, depending on the context. WSD can help to resolve the ambiguity of these terms and select the most appropriate sense for the text and the query. [This can improve the quality and relevance of the summaries for biomedical texts, which are often used for research, diagnosis, or education purposes](https://direct.mit.edu/coli/article/47/4/813/106774/Abstractive-Text-Summarization-Enhancing-Sequence)","x":-2598,"y":1360,"width":958,"height":140},
		{"id":"d8a40ee5062777e4","type":"text","text":"These texts contain many terms and concepts that have different meanings and levels of difficulty in different subjects and grades. For example, the word “kuasa” can mean power, exponent, or authority, depending on the context. WSD can help to resolve the ambiguity of these terms and select the most appropriate sense for the text and the query. [This can improve the quality and relevance of the summaries for education texts, which are often used for learning, teaching, or assessment purposes](https://direct.mit.edu/coli/article/47/4/813/106774/Abstractive-Text-Summarization-Enhancing-Sequence)","x":-2597,"y":660,"width":955,"height":110},
		{"id":"f1b41ac83c4c29b3","type":"text","text":"These texts contain many words and names that have different meanings and associations in different regions, cultures, or events. For example, the word “melaka” can mean a state, a city, or a fruit, depending on the context. WSD can help to identify the correct sense of these words and names for the text and the query. [This can enhance the readability and coherence of the summaries for tourism texts, which are often used for promotion, information, or recommendation purposes](https://link.springer.com/book/10.1007/978-1-4020-4809-8)","x":-2595,"y":828,"width":951,"height":118},
		{"id":"4959b5fcf35fcff5","type":"text","text":"Pre-Processing","x":-1539,"y":252,"width":250,"height":60},
		{"id":"68173c08de2f4232","type":"text","text":"Machine Learning","x":-1539,"y":400,"width":250,"height":60},
		{"id":"e1bbba812735ec96","type":"text","text":"Post-Processing","x":-1540,"y":541,"width":250,"height":60},
		{"id":"6cc2fbcd8d3c8080","type":"text","text":"This involves using WSD to transform the generated summaries into a human-readable form, by replacing senses, synonyms, or hypernyms with words that are more appropriate and fluent. WSD can also help to refine and polish the summaries, by correcting errors, removing redundancy, and adding punctuation.","x":-2597,"y":522,"width":962,"height":99},
		{"id":"2866339ee2af8031","type":"text","text":"This involves using WSD to enhance the performance of machine learning models, such as neural networks, that are trained to generate summaries in an abstractive way. WSD can help the models to capture the semantic and syntactic features of the text and the query, and to generate summaries that are more accurate and coherent.","x":-2595,"y":387,"width":958,"height":86},
		{"id":"51af25c8da850e09","type":"text","text":"This involves using WSD to transform the text and the query into a generalized form, by replacing words with their senses, synonyms, or hypernyms. This can reduce the ambiguity and variability of natural language, and make the text and the query more compatible and comparable.","x":-2595,"y":239,"width":952,"height":87},
		{"id":"6a8a879ee3af731d","type":"file","file":"Pasted image 20240206175430.png","x":-3420,"y":430,"width":125,"height":293},
		{"id":"de5f37d297f2da21","type":"file","file":"Pasted image 20240206180750.png","x":-3260,"y":152,"width":110,"height":261},
		{"id":"c7ec22484c81df98","type":"file","file":"Pasted image 20240206180826.png","x":-3094,"y":326,"width":191,"height":215},
		{"id":"6310c02949300a16","type":"text","text":"This paper proposes a hybrid approach of unsupervised and knowledge-based WSD for Malay words, using external sources such as Malay Wordnet and Google search engine. [The paper claims that the proposed algorithm outperforms other methods such as Lesk, Yarowsky, and Google Translate](https://www.researchtrend.net/ijet/pdf/51%20Improved%20Algorithm%20for%20Malay%20Word%20Sense%20Disambiguation-3259-%20Mohd%20Pouzi%20Hamzah.pdf)","x":1958,"y":-601,"width":953,"height":104},
		{"id":"47c89fe0f7712b51","type":"text","text":"This paper proposes a Malay WSD method that uses cross-language learning sources such as AsianWordNet and PrincetonWordNet. [The paper shows that the proposed method achieves better accuracy than the baseline method](https://www.ingentaconnect.com/contentone/asp/asl/2017/00000023/00000011/art00192)","x":1958,"y":-480,"width":953,"height":76},
		{"id":"da02ad764a925ed5","type":"text","text":"This paper proposes a method for WSD using fuzzy semantic-based similarity measure, which compares the similarity of two sentences based on their semantic features. [The paper evaluates the method on a Malay corpus and shows that it performs well](https://mjoc.uitm.edu.my/main/index.php/journal/17-volume-3-2-2018/42-4890)","x":1958,"y":-387,"width":953,"height":92},
		{"id":"c6875f685da093a9","type":"text","text":"[This paper discusses how WSD can improve the performance and effectiveness of query-based text summarization for Malay language, by using common sense knowledge and semantic relatedness measure](https://link.springer.com/article/10.1007/s40747-019-0115-2)","x":1958,"y":-278,"width":953,"height":72},
		{"id":"ace47e52ce64c545","type":"text","text":"[This paper describes how WSD can enhance the information retrieval and query expansion for Malay language, by using a hybrid approach of unsupervised and knowledge-based methods](https://jtec.utem.edu.my/jtec/article/view/2929)","x":1958,"y":-189,"width":953,"height":50},
		{"id":"f9d0539c133c1396","type":"text","text":"This paper reviews the existing WSD approaches on unstructured texts, and identifies the gaps and challenges of the current research. [It also suggests some future directions and opportunities for WSD, especially for low-resource languages such as Malay](https://link.springer.com/content/pdf/10.1007/s40747-019-0115-2.pdf)","x":1958,"y":-123,"width":953,"height":98},
		{"id":"10bcbb890b36e5b1","type":"text","text":"Improving the quality and relevance of information retrieval and query expansion for Malay language users, by resolving the ambiguity of words and selecting the most appropriate senses in the text and the query.","x":1958,"y":-6,"width":953,"height":82},
		{"id":"b4acdb898dbef1d4","type":"text","text":"Enhancing the readability and coherence of text summaries for Malay language users, by using WSD to generate summaries that are more accurate, informative, and concise.","x":1958,"y":87,"width":953,"height":76,"color":"4"},
		{"id":"1783ea5e65181ec5","type":"text","text":"Advancing the research and development of natural language processing (NLP) for Malay language, by creating and evaluating new methods and resources for WSD and text summarization, and by addressing the challenges and gaps of the current state-of-the-art.","x":1958,"y":172,"width":953,"height":102,"color":"4"},
		{"id":"1c784e4ba841c162","type":"text","text":"Promoting the preservation and dissemination of Malay language and culture, by using WSD and text summarization to facilitate the access and understanding of Malay texts, such as literature, history, and news.","x":1958,"y":283,"width":953,"height":62,"color":"4"},
		{"id":"d97e78907e16da62","type":"text","text":"Impact","x":1602,"y":133,"width":250,"height":60},
		{"id":"0025b4418f901b64","type":"text","text":"Malay Text Summarization","x":1080,"y":-116,"width":250,"height":60},
		{"id":"a2381129b389607f","type":"text","text":"To improve the quality and relevance of the generated summaries","x":104,"y":-25,"width":540,"height":60},
		{"id":"f083c1584a60cbde","type":"text","text":"The scarcity and quality of resources and data for Malay language, such as dictionaries, wordnets, corpora, and annotated texts, that are needed for WSD and text summarization methods and evaluation.","x":1955,"y":387,"width":956,"height":60},
		{"id":"b6c16ddc43ac8ced","type":"text","text":"The complexity and diversity of Malay language, such as the use of different dialects, scripts, loanwords, and code-switching, that can affect the ambiguity and variability of words and their senses.","x":1953,"y":463,"width":958,"height":60},
		{"id":"1a2aeaed990b2a8d","type":"text","text":"Challenges","x":1602,"y":463,"width":250,"height":60},
		{"id":"ca6fd4e8408d1942","type":"text","text":"The lack of baseline and benchmark systems and metrics for Malay language WSD and text summarization, that can provide a standard and consistent way to compare and measure the performance and quality of the systems and outputs.","x":1951,"y":540,"width":960,"height":60},
		{"id":"9df1da154866f12a","type":"text","text":"[This paper describes the challenges and opportunities of applying WSD for Malay language, and proposes a method that uses a hybrid approach of unsupervised and knowledge-based methods](https://link.springer.com/chapter/10.1007/978-981-10-8276-4_14)","x":1958,"y":-680,"width":954,"height":65},
		{"id":"952bd46d388f2b38","type":"text","text":" [This paper discusses the challenges and limitations of existing text summarization methods and resources for Malay language, and proposes a hybrid approach that combines statistical and linguistic techniques](https://www.iiis.org/CDs2010/CD2010SCI/IMETI_2010/PapersPdf/FA180HB.pdf)","x":1959,"y":-760,"width":953,"height":62},
		{"id":"ce55a9b764d74aec","type":"text","text":"Papers","x":1600,"y":-434,"width":250,"height":60},
		{"id":"4c0bcab77aef5b34","type":"text","text":"Graph-based Method","x":-3435,"y":-992,"width":250,"height":60},
		{"id":"dfbb4a0871befbef","type":"text","text":"Graph-based methods can solve word sense disambiguation (WSD) in Malay language text summarization by using various algorithms, such as PageRank, HITS, or LexRank, to rank the nodes according to their importance and relevance, and extract the most salient ones for the summary.","x":-4460,"y":-1227,"width":922,"height":87},
		{"id":"951d87d7fd4f284c","type":"text","text":"Graph Based WSD: This paper describes a graph-based WSD method that uses WordNet and PageRank to find the most relevant sense of each word in the text. [The paper also evaluates the method on a standard WSD dataset](https://link.springer.com/chapter/10.1007/978-981-10-2471-9_64)","x":-4460,"y":-1121,"width":918,"height":60},
		{"id":"68b7ea50378dad67","type":"text","text":"Correlation between different WSD methods and summarization effectiveness in biomedical textsThis paper investigates the impact of different WSD approaches on the performance of a graph-based summarizer for biomedical texts. [It shows that WSD can improve the quality and relevance of the summaries by selecting the most appropriate senses of the words in the text and the query](https://www.hindawi.com/journals/ddns/2021/2822126/)","x":-4460,"y":-1040,"width":917,"height":126},
		{"id":"e98375412b2bf61b","type":"text","text":"Word Sense Induction Disambiguation Using Hierachical Random Graphs: This paper proposes a method for WSD using hierarchical random graphs, which are graphs that can capture the hierarchical structure of the senses. [The paper also applies the method to text summarization by using the induced senses to rank the sentences](https://web.eecs.umich.edu/~mihalcea/papers/sinha.ieee07.pdf)","x":-4461,"y":-892,"width":918,"height":85},
		{"id":"33c67b8e464be310","type":"text","text":"Learning with Fuzzy Hypergraphs: A Topical Approach to Query-oriented Text Summarization; This paper describes a graph-based method for extractive document summarization that uses fuzzy hypergraphs to represent the text and the query. [The paper claims that the method can capture the topical structure and relevance of the text and the query, and generate summaries that are more informative and coherent](https://utmscholar.utm.my/Scholar/ScholarInfoDetails/v1l1)","x":-4780,"y":-759,"width":860,"height":119},
		{"id":"06e570fe4b89d237","type":"text","text":"Text Summarization Using Morphological Filtering of Intuitionistic Fuzzy Hypergraph: This paper proposes a novel method for extractive text summarization that uses intuitionistic fuzzy hypergraph to model the document. [The paper shows that the method can use morphological filtering to create concise summaries that preserve the main information and meaning of the document](https://utmscholar.utm.my/Scholar/ScholarInfoDetails/3J2z)","x":-4780,"y":-618,"width":860,"height":118},
		{"id":"fe9cf5ff27861830","type":"text","text":"Fuzzy Hypergraph","x":-3793,"y":-589,"width":250,"height":60},
		{"id":"3787af6ea6184ef7","type":"text","text":"The **phenomenon** of a word having more than one meaning or sense","x":-1111,"y":-1440,"width":471,"height":64},
		{"id":"099b74e46fd9d96b","type":"text","text":"Ontology","x":-3435,"y":-1440,"width":250,"height":60},
		{"id":"7fc716d788454c18","type":"text","text":"Ontology is a type of knowledge base that represents the concepts and relations in a specific domain or field. Ontology can be one part of solving word sense disambiguation (WSD) in Malay text summarization, by providing useful knowledge for finding the correct sense of each word in the text and the query, and for generating summaries that are accurate, relevant, and coherent.","x":-4460,"y":-1477,"width":918,"height":135},
		{"id":"2388b7a904da2228","type":"text","text":"  Building an Ontology-Based Multilingual Lexicon for WSD is a paper that describes a method for building a multilingual lexicon based on ontology, which can be used for WSD and machine translation. [The paper shows that the ontology-based lexicon can capture the semantic and syntactic features of words in different languages, such as Malay, English, and French](https://liantze.penguinattack.org/files/publications/papillon04.pdf)","x":-5560,"y":-1527,"width":967,"height":87},
		{"id":"5dca9ebb448608b2","type":"text","text":"Corpus-based Ontology Learning for WSD is a paper that proposes a method for learning ontology from a corpus, which can be used for WSD and text summarization. [The paper shows that the corpus-based ontology can represent the domain knowledge and the word senses in a structured and hierarchical way](https://aclanthology.org/Y03-1044.pdf)","x":-5560,"y":-1395,"width":975,"height":95},
		{"id":"cfbd905798b3685e","type":"text","text":"Extractive Summary","x":355,"y":686,"width":250,"height":60},
		{"id":"eb5792e3660fa5bf","type":"text","text":"Identifying the correct sense of each word in the text and the query, and then measuring the semantic relatedness between them. This way, the sentences that are most relevant to the query can be extracted and ranked according to their importance.","x":272,"y":833,"width":417,"height":192},
		{"id":"46d9db928b7e67e6","type":"text","text":"Enabling the use of knowledge-based and semantic-based methods that can generalize and paraphrase the content of the text. For example, WSD can help in replacing words with their synonyms or hypernyms, or using ontological knowledge to abstract the text into a generalized form. This can reduce the redundancy and verbosity of the text and make the summary more informative and readable.","x":700,"y":833,"width":560,"height":192},
		{"id":"3f56e96007dbac6a","type":"text","text":"Abstractive Summary","x":855,"y":687,"width":250,"height":60},
		{"id":"f136f6ef0d7f5f21","type":"text","text":"Types","x":605,"y":492,"width":250,"height":60},
		{"id":"81f3ca99c010bc4c","type":"text","text":"Existing Libraries","x":-1039,"y":1720,"width":250,"height":60},
		{"id":"c00b8a31bddb8aed","type":"text","text":"[Malaya](https://github.com/mesolitica/malaya)","x":-1504,"y":1589,"width":250,"height":60},
		{"id":"6d23886a2cc82bd8","type":"text","text":"[Paraphrase Tool](https://paraphrasetool.com/langs/malay-summarizing-tool)","x":-1504,"y":1720,"width":250,"height":60},
		{"id":"73e46c0619920e8e","type":"text","text":"[SEAlang Library](http://sealang.net/malay/corpus.htm)","x":-1504,"y":1840,"width":250,"height":60},
		{"id":"eb338aa807463fe2","type":"text","text":"Malaya is a natural language toolkit for Malay language, which provides various models and functions for text processing, such as word sense disambiguation (WSD) and text summarization. Malaya can solve the WSD problem in Malay text summarization by using neural network methods, such as sequence-to-sequence, transformer, and reinforcement learning, to generate abstractive summaries for Malay texts. Malaya can also use WSD to transform the text and the query into a generalized form, and to transform the generated summaries into a human-readable form.","x":-2598,"y":1546,"width":1008,"height":147},
		{"id":"2341736de1bcaace","type":"text","text":"A collection of texts that can provide the context and the usage of words and their senses in a specific domain or field. Corpus can help in finding the correct sense of each word in the text and the query, by using statistical or machine learning methods that measure the frequency, distribution, or similarity of words and their senses.","x":-2598,"y":2002,"width":1362,"height":78},
		{"id":"5ba8e67feb30a5aa","type":"text","text":"A source of data that can be used for training and evaluating WSD and text summarization systems, by using annotated or labeled texts that indicate the correct sense of each word or the best summary of each text. Corpus can help in improving the performance and quality of WSD and text summarization systems, by using supervised or unsupervised methods that learn from the data and the annotations.","x":-2598,"y":2120,"width":1362,"height":100},
		{"id":"8b680175a064c91c","type":"text","text":"Corpus","x":-1039,"y":2090,"width":250,"height":60},
		{"id":"e79f17075c9027ae","type":"file","file":"Pasted image 20240206185051.png","x":-1600,"y":2260,"width":364,"height":400},
		{"id":"11eb351835229c63","type":"text","text":"WSD using Fuzzy Semantic-Based String Similarity Measure: This paper presents a method for WSD using fuzzy semantic-based similarity measure, which compares the similarity of two sentences based on their semantic features. [The paper evaluates the method on a Malay corpus and shows that it performs well](https://arxiv.org/abs/1906.09445)","x":-4780,"y":-480,"width":860,"height":84},
		{"id":"d4fd79ddf03fc76f","type":"text","text":"Fuzzy hypergraph partitioning: This is a method that divides the fuzzy hypergraph into smaller and more coherent subgraphs, based on the similarity and relevance of the words and their senses. This can reduce the complexity and ambiguity of the WSD problem, and make it easier to select the most appropriate sense for each word in the text and the query.","x":-5280,"y":-371,"width":1024,"height":108},
		{"id":"22858475c9611bc3","type":"text","text":"Fuzzy hypergraph ranking: This is a method that assigns a score or a rank to each word and its sense in the fuzzy hypergraph, based on the importance and saliency of the word and its sense in the text and the query. This can improve the accuracy and efficiency of the WSD problem, and make it easier to extract the most salient words and their senses for the summary.","x":-5280,"y":-248,"width":1024,"height":88},
		{"id":"2894af0e70cc91e9","type":"text","text":"Fuzzy hypergraph summarization: This is a method that uses the fuzzy hypergraph to generate summaries in an abstractive way, by using the words and their senses as the building blocks of the summary. This can enhance the readability and coherence of the summary, by using the most appropriate words and their senses in the summary.","x":-5280,"y":-140,"width":1027,"height":84},
		{"id":"f7d1cb0c4572350f","type":"text","text":"Type of Solution","x":-4170,"y":-234,"width":250,"height":60},
		{"id":"3a75bde0172aa40e","type":"text","text":"WSD can be used to select and rank the most important sentences from the original text, based on the semantic relatedness and relevance of the words and their senses in the text and the query. For example,  [is a paper that proposes a query-based text summarization method that uses WSD to generate extractive summaries for Malay texts](https://www.scrapehero.com/nlp-basics-abstractive-and-extractive-text-summarization/)","x":-260,"y":833,"width":509,"height":192},
		{"id":"47456b2481254077","type":"text","text":"WSD can be used to generate and rewrite the main information and meaning of the original text, using the most appropriate words and their senses in the summary.","x":1320,"y":833,"width":453,"height":192},
		{"id":"a1f34ce34fd0dde2","type":"text","text":"[Abstractive Text Summarization: Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization](https://direct.mit.edu/coli/article/47/4/813/106774/Abstractive-Text-Summarization-Enhancing-Sequence) : This paper presents a novel framework that combines sequence-to-sequence neural-based text summarization along with structure and semantic-based methodologies. The framework uses WSD to transform ordinary text into a generalized form, and then uses deep learning models to generate summaries in a generalized form. The framework also uses WSD to transform the generalized summaries into a final, human-readable form.\n","x":1147,"y":1120,"width":800,"height":192},
		{"id":"ae54bcbd8d7a3bb6","type":"file","file":"Untitled Diagram-Page-1.drawio (3).png","x":807,"y":-1387,"width":920,"height":849},
		{"id":"882b58fd962292e3","type":"text","text":"Types","x":-261,"y":-1033,"width":250,"height":60},
		{"id":"41d8d3a7db6d186e","type":"text","text":"Extractive Summary","x":-436,"y":-1186,"width":250,"height":66},
		{"id":"28c8c2e8ce8d1f4b","type":"text","text":"Selecting the most important sentences or phrases from the original text and concatenating them to form a summary","x":-461,"y":-1357,"width":301,"height":120},
		{"id":"02ec00e8f1b48138","type":"text","text":"Generating new sentences that convey the main information and meaning of the original text in a concise and coherent way","x":-120,"y":-1357,"width":317,"height":120},
		{"id":"fd05f3e0189b8c2e","type":"text","text":"Abstractive Summary","x":-87,"y":-1186,"width":250,"height":66},
		{"id":"2c2136c876ea3733","type":"text","text":"Input","x":270,"y":-1033,"width":250,"height":60},
		{"id":"4795738e3fb76e1a","type":"text","text":"Single Document","x":212,"y":-1180,"width":250,"height":60},
		{"id":"a362b970cf3e3abf","type":"text","text":"Multi-Document","x":520,"y":-1180,"width":250,"height":60}
	],
	"edges":[
		{"id":"8c2ea00712949b0d","fromNode":"90cec71e9bb2b6e7","fromSide":"top","toNode":"aae8dc8f89f6adc9","toSide":"bottom","label":"Definition"},
		{"id":"a5427a0f3b7315d1","fromNode":"90cec71e9bb2b6e7","fromSide":"left","toNode":"a52056f02595ba82","toSide":"right","label":"Problem"},
		{"id":"f986d33ce3b34afe","fromNode":"90cec71e9bb2b6e7","fromSide":"right","toNode":"ae54bcbd8d7a3bb6","toSide":"left","label":"How it started?"},
		{"id":"a3d7529774afb1ff","fromNode":"a52056f02595ba82","fromSide":"left","toNode":"bcde28ab5ef3abc2","toSide":"right"},
		{"id":"0e0b97f05cf6a5b3","fromNode":"bcde28ab5ef3abc2","fromSide":"left","toNode":"99ecbf6c5803bc3f","toSide":"right"},
		{"id":"56067448eac3d3d1","fromNode":"bcde28ab5ef3abc2","fromSide":"left","toNode":"44e691f54b852429","toSide":"right"},
		{"id":"d68af40ea37b748d","fromNode":"bcde28ab5ef3abc2","fromSide":"left","toNode":"0f12e35dbc77bd46","toSide":"right"},
		{"id":"10f1c5b2495407bc","fromNode":"bcde28ab5ef3abc2","fromSide":"left","toNode":"4cba1b3b04c46682","toSide":"right"},
		{"id":"4e5ed09b6742f0b0","fromNode":"99ecbf6c5803bc3f","fromSide":"left","toNode":"d29ce87c068e22b2","toSide":"right"},
		{"id":"60be876f0e16cef5","fromNode":"44e691f54b852429","fromSide":"left","toNode":"26bb0b984e5bc95e","toSide":"right"},
		{"id":"a5bbc4cdfcbca087","fromNode":"0f12e35dbc77bd46","fromSide":"left","toNode":"4f49bc8097c8b200","toSide":"right"},
		{"id":"aeb255f1beab9ff0","fromNode":"4cba1b3b04c46682","fromSide":"left","toNode":"0d2b249776ff9773","toSide":"right"},
		{"id":"3e44f589799f5d84","fromNode":"a52056f02595ba82","fromSide":"left","toNode":"e868388bf8a96d92","toSide":"right"},
		{"id":"390e95fd618f6560","fromNode":"e868388bf8a96d92","fromSide":"left","toNode":"12ba9d718f56f0cc","toSide":"right"},
		{"id":"5aead6111dfc90a7","fromNode":"e868388bf8a96d92","fromSide":"left","toNode":"77b585d12f204d43","toSide":"right"},
		{"id":"6b467240be7995c4","fromNode":"e868388bf8a96d92","fromSide":"left","toNode":"6660aca082f74dc0","toSide":"right"},
		{"id":"27c7e2e6a44367d7","fromNode":"12ba9d718f56f0cc","fromSide":"left","toNode":"4b7cbbab26e16db5","toSide":"right"},
		{"id":"209e872cf683e5e2","fromNode":"77b585d12f204d43","fromSide":"left","toNode":"ccb3dde52b1bd5f5","toSide":"right"},
		{"id":"d3b8ff142d00709c","fromNode":"6660aca082f74dc0","fromSide":"left","toNode":"63c8f4172518c95e","toSide":"right"},
		{"id":"8c26c803932b6aa9","fromNode":"d29ce87c068e22b2","fromSide":"left","toNode":"db2642e5d30ad0d5","toSide":"right"},
		{"id":"0b907eb310ba6ff5","fromNode":"4f49bc8097c8b200","fromSide":"left","toNode":"3b426eb70886cfc2","toSide":"right"},
		{"id":"818854ae3f433c47","fromNode":"0d2b249776ff9773","fromSide":"left","toNode":"46bf6cd2fcfe4d3f","toSide":"right"},
		{"id":"ceae052e5a6b1875","fromNode":"a52056f02595ba82","fromSide":"bottom","toNode":"a2381129b389607f","toSide":"top","label":"Correlation"},
		{"id":"c7981d3e4dab267e","fromNode":"882b58fd962292e3","fromSide":"top","toNode":"fd05f3e0189b8c2e","toSide":"bottom"},
		{"id":"de0d36036df72a5a","fromNode":"41d8d3a7db6d186e","fromSide":"top","toNode":"28c8c2e8ce8d1f4b","toSide":"bottom"},
		{"id":"c338de10da520ec4","fromNode":"fd05f3e0189b8c2e","fromSide":"top","toNode":"02ec00e8f1b48138","toSide":"bottom"},
		{"id":"93d040a322f856cd","fromNode":"f136f6ef0d7f5f21","fromSide":"left","toNode":"cfbd905798b3685e","toSide":"top"},
		{"id":"60d39625c82c766e","fromNode":"cfbd905798b3685e","fromSide":"bottom","toNode":"eb5792e3660fa5bf","toSide":"top"},
		{"id":"ac7035feaef9b5b9","fromNode":"f136f6ef0d7f5f21","fromSide":"right","toNode":"3f56e96007dbac6a","toSide":"top"},
		{"id":"ab78b9e0c0ba30d6","fromNode":"3f56e96007dbac6a","fromSide":"bottom","toNode":"46d9db928b7e67e6","toSide":"top"},
		{"id":"b8ca0954fe465c0e","fromNode":"47456b2481254077","fromSide":"bottom","toNode":"a1f34ce34fd0dde2","toSide":"top"},
		{"id":"7fc7bafabf99674c","fromNode":"a2381129b389607f","fromSide":"bottom","toNode":"f136f6ef0d7f5f21","toSide":"top"},
		{"id":"e66e109b4d80272f","fromNode":"a2381129b389607f","fromSide":"right","toNode":"0025b4418f901b64","toSide":"left"},
		{"id":"7b23722086ed4195","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"6310c02949300a16","toSide":"left"},
		{"id":"b948b507dcc2717a","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"47c89fe0f7712b51","toSide":"left"},
		{"id":"c9c6e46124749216","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"da02ad764a925ed5","toSide":"left"},
		{"id":"25cfa53dbf046f2b","fromNode":"a52056f02595ba82","fromSide":"left","toNode":"266d164a58e929bb","toSide":"right"},
		{"id":"1523701d6556eabb","fromNode":"266d164a58e929bb","fromSide":"left","toNode":"4f376e4542b3c237","toSide":"right"},
		{"id":"7328cc995193e14f","fromNode":"266d164a58e929bb","fromSide":"left","toNode":"ccbe89ec97449441","toSide":"right"},
		{"id":"7c6d4d40ce90bebc","fromNode":"ccbe89ec97449441","fromSide":"left","toNode":"be8a256b3777488d","toSide":"right"},
		{"id":"6619a8b6d7348cb2","fromNode":"ccbe89ec97449441","fromSide":"left","toNode":"6596d1f2650db256","toSide":"right"},
		{"id":"b2b202b609892ed8","fromNode":"ccbe89ec97449441","fromSide":"left","toNode":"216fd7d002d3fe5d","toSide":"right"},
		{"id":"6948ae45a3d4204a","fromNode":"ccbe89ec97449441","fromSide":"left","toNode":"3189b4c968947b73","toSide":"right"},
		{"id":"fe5ea252b33fbdce","fromNode":"be8a256b3777488d","fromSide":"left","toNode":"b9419e6c934ae2e3","toSide":"right"},
		{"id":"64de31a97b33914b","fromNode":"6596d1f2650db256","fromSide":"left","toNode":"0c9064f04dd4ee64","toSide":"right"},
		{"id":"3778c77a19615583","fromNode":"216fd7d002d3fe5d","fromSide":"left","toNode":"d8d2231a8f7374f7","toSide":"right"},
		{"id":"89ea9ca2b208abe7","fromNode":"3189b4c968947b73","fromSide":"left","toNode":"f5fb2b7887673b15","toSide":"right"},
		{"id":"cb3acda510c57265","fromNode":"0025b4418f901b64","fromSide":"right","toNode":"d97e78907e16da62","toSide":"left"},
		{"id":"e6da9876e4e388aa","fromNode":"0025b4418f901b64","fromSide":"right","toNode":"ce55a9b764d74aec","toSide":"left"},
		{"id":"2581469552ac4320","fromNode":"d97e78907e16da62","fromSide":"right","toNode":"10bcbb890b36e5b1","toSide":"left"},
		{"id":"0a45c41c5ffce983","fromNode":"d97e78907e16da62","fromSide":"right","toNode":"b4acdb898dbef1d4","toSide":"left"},
		{"id":"bdc474e9d2358be4","fromNode":"d97e78907e16da62","fromSide":"right","toNode":"1783ea5e65181ec5","toSide":"left"},
		{"id":"9f95eb4748504fe4","fromNode":"d97e78907e16da62","fromSide":"right","toNode":"1c784e4ba841c162","toSide":"left"},
		{"id":"0063ef307b8a1a09","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"c6875f685da093a9","toSide":"left"},
		{"id":"d423515c169d9b7e","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"ace47e52ce64c545","toSide":"left"},
		{"id":"5ce3f83e0c4382cb","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"f9d0539c133c1396","toSide":"left"},
		{"id":"b96cf47b7b806cd4","fromNode":"a52056f02595ba82","fromSide":"top","toNode":"70364c142da1dadc","toSide":"right","label":"Definition"},
		{"id":"abb1c632f1d48de7","fromNode":"a52056f02595ba82","fromSide":"left","toNode":"2bb6bf5b7a9df6f0","toSide":"right"},
		{"id":"93613f2d18460262","fromNode":"2bb6bf5b7a9df6f0","fromSide":"left","toNode":"4959b5fcf35fcff5","toSide":"right"},
		{"id":"e74abba214a94885","fromNode":"2bb6bf5b7a9df6f0","fromSide":"left","toNode":"68173c08de2f4232","toSide":"right"},
		{"id":"cc9ae3c8232e3280","fromNode":"2bb6bf5b7a9df6f0","fromSide":"left","toNode":"e1bbba812735ec96","toSide":"right"},
		{"id":"e8d0d9a92169c668","fromNode":"4959b5fcf35fcff5","fromSide":"left","toNode":"51af25c8da850e09","toSide":"right"},
		{"id":"8888f4b88aa1cdae","fromNode":"68173c08de2f4232","fromSide":"left","toNode":"2866339ee2af8031","toSide":"right"},
		{"id":"efe1c6110b638c3c","fromNode":"e1bbba812735ec96","fromSide":"left","toNode":"6cc2fbcd8d3c8080","toSide":"right"},
		{"id":"1b1b451ab40b7590","fromNode":"a52056f02595ba82","fromSide":"left","toNode":"13c2b5929f44cce4","toSide":"right"},
		{"id":"d1c6ff4b7b4ec196","fromNode":"13c2b5929f44cce4","fromSide":"left","toNode":"be3172ffa589942f","toSide":"right"},
		{"id":"2bf77ac612bc7098","fromNode":"13c2b5929f44cce4","fromSide":"left","toNode":"0f75e034b5ae2f3c","toSide":"right"},
		{"id":"7014bf33fa26bff2","fromNode":"13c2b5929f44cce4","fromSide":"left","toNode":"4501943dcecc92d9","toSide":"right"},
		{"id":"422df072cb849f0a","fromNode":"13c2b5929f44cce4","fromSide":"left","toNode":"cc8c96281fecf1cc","toSide":"right"},
		{"id":"92be4aeb177f8ee3","fromNode":"13c2b5929f44cce4","fromSide":"left","toNode":"df08c877e98f46ac","toSide":"right"},
		{"id":"733df19a92e2d6cf","fromNode":"df08c877e98f46ac","fromSide":"left","toNode":"70028197c6b314fb","toSide":"right"},
		{"id":"2e035ee778619177","fromNode":"cc8c96281fecf1cc","fromSide":"left","toNode":"7570e9561d79be61","toSide":"right"},
		{"id":"e18f0b3a1f64192f","fromNode":"4501943dcecc92d9","fromSide":"left","toNode":"59fa4ae03e12eb23","toSide":"right"},
		{"id":"ce8eb70b35502985","fromNode":"0f75e034b5ae2f3c","fromSide":"left","toNode":"f1b41ac83c4c29b3","toSide":"right"},
		{"id":"2d2197bca8fbad12","fromNode":"be3172ffa589942f","fromSide":"left","toNode":"d8a40ee5062777e4","toSide":"right"},
		{"id":"33bdc9860d1ebda5","fromNode":"6cc2fbcd8d3c8080","fromSide":"left","toNode":"6a8a879ee3af731d","toSide":"right"},
		{"id":"7a0ed1eecae165f2","fromNode":"51af25c8da850e09","fromSide":"left","toNode":"de5f37d297f2da21","toSide":"right"},
		{"id":"91b50b7f37da0f1d","fromNode":"2866339ee2af8031","fromSide":"left","toNode":"c7ec22484c81df98","toSide":"right"},
		{"id":"469bb37e2d23108b","fromNode":"90cec71e9bb2b6e7","fromSide":"bottom","toNode":"a2381129b389607f","toSide":"top"},
		{"id":"978f4a4d8f2c13c8","fromNode":"a2381129b389607f","fromSide":"bottom","toNode":"1a2aeaed990b2a8d","toSide":"left"},
		{"id":"28af9bfc64625b14","fromNode":"1a2aeaed990b2a8d","fromSide":"right","toNode":"f083c1584a60cbde","toSide":"left"},
		{"id":"36f5eb71f1ec52e0","fromNode":"1a2aeaed990b2a8d","fromSide":"right","toNode":"b6c16ddc43ac8ced","toSide":"left"},
		{"id":"203912b54358d4ce","fromNode":"1a2aeaed990b2a8d","fromSide":"right","toNode":"ca6fd4e8408d1942","toSide":"left"},
		{"id":"3b11839594eeebb9","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"9df1da154866f12a","toSide":"left"},
		{"id":"ea73fc8675d32490","fromNode":"ce55a9b764d74aec","fromSide":"right","toNode":"952bd46d388f2b38","toSide":"left"},
		{"id":"89c56af60d8ee2fb","fromNode":"3b426eb70886cfc2","fromSide":"left","toNode":"4c0bcab77aef5b34","toSide":"right"},
		{"id":"d6adb6f45a3b6ffa","fromNode":"4c0bcab77aef5b34","fromSide":"left","toNode":"dfbb4a0871befbef","toSide":"right"},
		{"id":"364c5bcbabf04b2e","fromNode":"4c0bcab77aef5b34","fromSide":"left","toNode":"951d87d7fd4f284c","toSide":"right"},
		{"id":"582e0672aebca8ef","fromNode":"4c0bcab77aef5b34","fromSide":"left","toNode":"68b7ea50378dad67","toSide":"right"},
		{"id":"a71c2a36f90f09cc","fromNode":"4c0bcab77aef5b34","fromSide":"left","toNode":"e98375412b2bf61b","toSide":"right"},
		{"id":"fe771ed9962c3462","fromNode":"4c0bcab77aef5b34","fromSide":"left","toNode":"fe9cf5ff27861830","toSide":"right"},
		{"id":"920005ad6d734b29","fromNode":"fe9cf5ff27861830","fromSide":"left","toNode":"33c67b8e464be310","toSide":"right"},
		{"id":"1442ec0767103895","fromNode":"fe9cf5ff27861830","fromSide":"left","toNode":"06e570fe4b89d237","toSide":"right"},
		{"id":"00e85dc3e9e1523b","fromNode":"fe9cf5ff27861830","fromSide":"left","toNode":"11eb351835229c63","toSide":"right"},
		{"id":"457be051b263b834","fromNode":"70364c142da1dadc","fromSide":"top","toNode":"3787af6ea6184ef7","toSide":"bottom","label":"Polysemy?"},
		{"id":"ff1e34f1a883f859","fromNode":"3b426eb70886cfc2","fromSide":"left","toNode":"099b74e46fd9d96b","toSide":"right"},
		{"id":"93fb2ef81f7a885b","fromNode":"099b74e46fd9d96b","fromSide":"left","toNode":"7fc716d788454c18","toSide":"right"},
		{"id":"ee98780c5b36a0e2","fromNode":"7fc716d788454c18","fromSide":"left","toNode":"2388b7a904da2228","toSide":"right"},
		{"id":"707f3e4108ce6542","fromNode":"7fc716d788454c18","fromSide":"left","toNode":"5dca9ebb448608b2","toSide":"right"},
		{"id":"8e3bd19e92714c30","fromNode":"a52056f02595ba82","fromSide":"bottom","toNode":"81f3ca99c010bc4c","toSide":"right"},
		{"id":"ff92e0e49da9f9a6","fromNode":"81f3ca99c010bc4c","fromSide":"left","toNode":"c00b8a31bddb8aed","toSide":"right"},
		{"id":"c2cbecee7ffd58ea","fromNode":"81f3ca99c010bc4c","fromSide":"left","toNode":"6d23886a2cc82bd8","toSide":"right"},
		{"id":"cb3630a542c9064d","fromNode":"81f3ca99c010bc4c","fromSide":"left","toNode":"73e46c0619920e8e","toSide":"right"},
		{"id":"64122b53468aa11b","fromNode":"c00b8a31bddb8aed","fromSide":"left","toNode":"eb338aa807463fe2","toSide":"right"},
		{"id":"47ef45f55eea5bf2","fromNode":"a52056f02595ba82","fromSide":"bottom","toNode":"8b680175a064c91c","toSide":"right"},
		{"id":"419627bf68c9a0bf","fromNode":"8b680175a064c91c","fromSide":"left","toNode":"2341736de1bcaace","toSide":"right"},
		{"id":"c556b57121308fd6","fromNode":"8b680175a064c91c","fromSide":"left","toNode":"5ba8e67feb30a5aa","toSide":"right"},
		{"id":"aba55842b6840f79","fromNode":"8b680175a064c91c","fromSide":"left","toNode":"e79f17075c9027ae","toSide":"right"},
		{"id":"0f91cdb45014e62f","fromNode":"fe9cf5ff27861830","fromSide":"left","toNode":"f7d1cb0c4572350f","toSide":"right"},
		{"id":"643adfc2c37cccb1","fromNode":"f7d1cb0c4572350f","fromSide":"left","toNode":"d4fd79ddf03fc76f","toSide":"right"},
		{"id":"af17ea5726c821c2","fromNode":"f7d1cb0c4572350f","fromSide":"left","toNode":"22858475c9611bc3","toSide":"right"},
		{"id":"518d57c4fb64db5f","fromNode":"f7d1cb0c4572350f","fromSide":"left","toNode":"2894af0e70cc91e9","toSide":"right"},
		{"id":"01e40090c60170d7","fromNode":"cfbd905798b3685e","fromSide":"bottom","toNode":"3a75bde0172aa40e","toSide":"top"},
		{"id":"93904ed7de652480","fromNode":"3f56e96007dbac6a","fromSide":"bottom","toNode":"47456b2481254077","toSide":"top"},
		{"id":"8ccf2b4f056996f3","fromNode":"aae8dc8f89f6adc9","fromSide":"top","toNode":"882b58fd962292e3","toSide":"bottom"},
		{"id":"0eb063b2a9a01897","fromNode":"882b58fd962292e3","fromSide":"top","toNode":"41d8d3a7db6d186e","toSide":"bottom"},
		{"id":"ff3c5d88007a7ab8","fromNode":"aae8dc8f89f6adc9","fromSide":"top","toNode":"2c2136c876ea3733","toSide":"bottom"},
		{"id":"0e96ed41df333909","fromNode":"2c2136c876ea3733","fromSide":"top","toNode":"4795738e3fb76e1a","toSide":"bottom"},
		{"id":"ab309f212f62ddf3","fromNode":"2c2136c876ea3733","fromSide":"top","toNode":"a362b970cf3e3abf","toSide":"bottom"}
	]
}