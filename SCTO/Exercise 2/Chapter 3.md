![](https://cdn.sketchbubble.com/pub/media/catalog/product/optimized1/2/4/2442a9d6d4639670d44d8128bb48b77e37686bf9537961e205a61aed56232949/word-sense-disambiguation-mc-slide2.png)

# WSD Approaches

Word sense disambiguation (WSD) is the task of identifying the correct meaning of a word in a given context, when the word has multiple possible meanings. There are various approaches and methods to solve this problem, depending on the source and type of knowledge used for disambiguation. In this chapter, we will review some of the main categories of WSD approaches, such as:

- Dictionary-based or knowledge-based approaches: These rely primarily on dictionaries, thesauri, and lexical knowledge bases, without using any corpus evidence. They use the definitions and relations of words in the knowledge sources to measure the similarity or overlap between the word senses and the context. [The Lesk algorithm is a classic example of this approach](https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_word_sense_disambiguation.htm)[1](https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_word_sense_disambiguation.htm).
- Supervised approaches: These use machine learning techniques to train a classifier for each word on a corpus of manually sense-annotated examples. They use various features, such as the surrounding words, the part-of-speech tags, the syntactic structure, and the semantic role of the word, to predict the most likely sense for a new occurrence of the word. [Decision trees, support vector machines, and neural networks are some of the common methods used in this approach](https://en.wikipedia.org/wiki/Word-sense_disambiguation)[2](https://en.wikipedia.org/wiki/Word-sense_disambiguation).
- Semi-supervised approaches: These use a combination of labeled and unlabeled data to improve the performance and coverage of WSD. They use techniques such as bootstrapping, co-training, self-training, and active learning to leverage the large amount of unlabeled data available for WSD. [They can also use external resources, such as parallel corpora, word embeddings, and knowledge graphs, to enrich the feature space and the sense inventory of the word](https://content.aucklanddesignmanual.co.nz/regulations/technical-guidance/wsd/details/guidance/introduction/sections/wsdapproachestostormwatermanagement/Pages/default.aspx)[3](https://content.aucklanddesignmanual.co.nz/regulations/technical-guidance/wsd/details/guidance/introduction/sections/wsdapproachestostormwatermanagement/Pages/default.aspx).
- Unsupervised approaches: These do not use any labeled data or predefined sense inventory, but rather cluster the occurrences of words based on their distributional similarity or contextual relatedness. They assume that each cluster corresponds to a different sense of the word, and assign a label to each cluster based on the most representative words or concepts. Topic models, word alignment models, and graph-based models are some of the popular methods used in this approach.

These are just some of the broad categories of WSD approaches, and there are many variations and hybrids of them in the literature. Each approach has its own advantages and disadvantages, and there is no single best approach for all words and domains. The choice of the best approach depends on the availability and quality of the data, the complexity and granularity of the word senses, the application and user requirements, and the evaluation criteria and metrics.

<iframe width="560" height="315" src="https://www.youtube.com/embed/bJQ24a1HYyU?si=0Pfj3oonxBZpcvd1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>